{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential,Model,initializers,layers,Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual_BottleNeck\n",
    "\n",
    "1. MobileNetV2:  Inverted Residuals  and Linear  Bottlenecks, Figure 4(d) 기반으로 작성\n",
    "\n",
    "2. Full-pre-activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Residual_BottleNeck_st_1_Block(x,expansion,input_channels,output_channels):\n",
    "    x1=layers.BatchNormalization()(x)\n",
    "    x1=layers.ReLU(max_value=6)(x1)\n",
    "    x1=layers.Conv2D(filters=input_channels*expansion,kernel_size=(1,1),strides=1,padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x)\n",
    "    x1=layers.ReLU(max_value=6)(x)\n",
    "    x1=layers.DepthwiseConv2D(kernel_size=(3,3),strides=1,padding='same')(x1)\n",
    "    x1=layers.Conv2D(filters=output_channels,kernel_size=(1,1),strides=1,padding='same')(x1)\n",
    "\n",
    "    x2= layers.Add()([x,x1])\n",
    "    return x2\n",
    "\n",
    "\n",
    "def Residual_BottleNeck_st_2_Block(x,expansion,input_channels,output_channels):\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU(max_value=6)(x)\n",
    "    x=layers.Conv2D(filters=input_channels*expansion,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU(max_value=6)(x)\n",
    "    x=layers.DepthwiseConv2D(kernel_size=(3,3),strides=2,padding='same')(x)\n",
    "    x=layers.Conv2D(filters=output_channels,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=Input(shape=(224,224,3))\n",
    "x=layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same')(input)\n",
    "\n",
    "#x=Residual_BottleNeck_st_1_Block(x,1,16)-> Add불가능(short-connection 불가능)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.Conv2D(filters=32,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.DepthwiseConv2D(kernel_size=(3,3),strides=1,padding='same')(x)\n",
    "x=layers.Conv2D(filters=16,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "\n",
    "x=Residual_BottleNeck_st_2_Block(x,6,16,24)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,24,24)\n",
    "\n",
    "x=Residual_BottleNeck_st_2_Block(x,6,24,32)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,32,32)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,32,32)\n",
    "\n",
    "x=Residual_BottleNeck_st_2_Block(x,6,32,64)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,64,64)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,64,64)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,64,64)\n",
    "\n",
    "#x=Residual_BottleNeck_st_1_Block(x,6,96,64)-> Add불가능(short-connection 불가능)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.Conv2D(filters=64*6,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.DepthwiseConv2D(kernel_size=(3,3),strides=1,padding='same')(x)\n",
    "x=layers.Conv2D(filters=96,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,96,96)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,96,96)\n",
    "\n",
    "x=Residual_BottleNeck_st_2_Block(x,6,96,160)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,160,160)\n",
    "x=Residual_BottleNeck_st_1_Block(x,6,160,160)\n",
    "\n",
    "#x=Residual_BottleNeck_st_1_Block(x,1,320)->Add 불가능(short-connection 불가능)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.Conv2D(filters=160*6,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU(max_value=6)(x)\n",
    "x=layers.DepthwiseConv2D(kernel_size=(3,3),strides=1,padding='same')(x)\n",
    "x=layers.Conv2D(filters=320,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "\n",
    "x=layers.Conv2D(filters=1280,kernel_size=(1,1),strides=1,padding='same')(x) \n",
    "x=layers.AveragePooling2D(pool_size=(7,7),strides=1)(x)\n",
    "x=layers.Conv2D(filters=1280,kernel_size=(1,1),strides=1,padding='same')(x)\n",
    "\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dense(units=10,activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,to_file='MobileNet_V2.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 112, 112, 32  896         ['input_6[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 112, 112, 32  128        ['conv2d_127[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_114 (ReLU)               (None, 112, 112, 32  0           ['batch_normalization_114[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 112, 112, 32  1056        ['re_lu_114[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 112, 112, 32  128        ['conv2d_128[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_115 (ReLU)               (None, 112, 112, 32  0           ['batch_normalization_115[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_57 (Depthwise  (None, 112, 112, 32  320        ['re_lu_115[0][0]']              \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 112, 112, 16  528         ['depthwise_conv2d_57[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 112, 112, 16  64         ['conv2d_129[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_116 (ReLU)               (None, 112, 112, 16  0           ['batch_normalization_116[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 112, 112, 96  1632        ['re_lu_116[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 112, 112, 96  384        ['conv2d_130[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_117 (ReLU)               (None, 112, 112, 96  0           ['batch_normalization_117[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_58 (Depthwise  (None, 56, 56, 96)  960         ['re_lu_117[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 56, 56, 24)   2328        ['depthwise_conv2d_58[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_119 (ReLU)               (None, 56, 56, 24)   0           ['conv2d_131[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_59 (Depthwise  (None, 56, 56, 24)  240         ['re_lu_119[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 56, 56, 24)   600         ['depthwise_conv2d_59[0][0]']    \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 56, 56, 24)   0           ['conv2d_131[0][0]',             \n",
      "                                                                  'conv2d_133[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 56, 56, 24)  96          ['add_41[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_120 (ReLU)               (None, 56, 56, 24)   0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 56, 56, 144)  3600        ['re_lu_120[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 56, 56, 144)  576        ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_121 (ReLU)               (None, 56, 56, 144)  0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_60 (Depthwise  (None, 28, 28, 144)  1440       ['re_lu_121[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 28, 28, 32)   4640        ['depthwise_conv2d_60[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_123 (ReLU)               (None, 28, 28, 32)   0           ['conv2d_135[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_61 (Depthwise  (None, 28, 28, 32)  320         ['re_lu_123[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 28, 28, 32)   1056        ['depthwise_conv2d_61[0][0]']    \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 28, 28, 32)   0           ['conv2d_135[0][0]',             \n",
      "                                                                  'conv2d_137[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_125 (ReLU)               (None, 28, 28, 32)   0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_62 (Depthwise  (None, 28, 28, 32)  320         ['re_lu_125[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 28, 28, 32)   1056        ['depthwise_conv2d_62[0][0]']    \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 28, 28, 32)   0           ['add_42[0][0]',                 \n",
      "                                                                  'conv2d_139[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 28, 28, 32)  128         ['add_43[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_126 (ReLU)               (None, 28, 28, 32)   0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 28, 28, 192)  6336        ['re_lu_126[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 28, 28, 192)  768        ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_127 (ReLU)               (None, 28, 28, 192)  0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_63 (Depthwise  (None, 14, 14, 192)  1920       ['re_lu_127[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 14, 14, 64)   12352       ['depthwise_conv2d_63[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_129 (ReLU)               (None, 14, 14, 64)   0           ['conv2d_141[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_64 (Depthwise  (None, 14, 14, 64)  640         ['re_lu_129[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 14, 14, 64)   4160        ['depthwise_conv2d_64[0][0]']    \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 14, 14, 64)   0           ['conv2d_141[0][0]',             \n",
      "                                                                  'conv2d_143[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_131 (ReLU)               (None, 14, 14, 64)   0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_65 (Depthwise  (None, 14, 14, 64)  640         ['re_lu_131[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 14, 14, 64)   4160        ['depthwise_conv2d_65[0][0]']    \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 14, 14, 64)   0           ['add_44[0][0]',                 \n",
      "                                                                  'conv2d_145[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_133 (ReLU)               (None, 14, 14, 64)   0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_66 (Depthwise  (None, 14, 14, 64)  640         ['re_lu_133[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 14, 14, 64)   4160        ['depthwise_conv2d_66[0][0]']    \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 14, 14, 64)   0           ['add_45[0][0]',                 \n",
      "                                                                  'conv2d_147[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 14, 14, 64)  256         ['add_46[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_134 (ReLU)               (None, 14, 14, 64)   0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 14, 14, 384)  24960       ['re_lu_134[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 14, 14, 384)  1536       ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_135 (ReLU)               (None, 14, 14, 384)  0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_67 (Depthwise  (None, 14, 14, 384)  3840       ['re_lu_135[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 14, 14, 96)   36960       ['depthwise_conv2d_67[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_137 (ReLU)               (None, 14, 14, 96)   0           ['conv2d_149[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_68 (Depthwise  (None, 14, 14, 96)  960         ['re_lu_137[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 14, 14, 96)   9312        ['depthwise_conv2d_68[0][0]']    \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 14, 14, 96)   0           ['conv2d_149[0][0]',             \n",
      "                                                                  'conv2d_151[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_139 (ReLU)               (None, 14, 14, 96)   0           ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_69 (Depthwise  (None, 14, 14, 96)  960         ['re_lu_139[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 14, 14, 96)   9312        ['depthwise_conv2d_69[0][0]']    \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 14, 14, 96)   0           ['add_47[0][0]',                 \n",
      "                                                                  'conv2d_153[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 14, 14, 96)  384         ['add_48[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_140 (ReLU)               (None, 14, 14, 96)   0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 14, 14, 576)  55872       ['re_lu_140[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 14, 14, 576)  2304       ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_141 (ReLU)               (None, 14, 14, 576)  0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_70 (Depthwise  (None, 7, 7, 576)   5760        ['re_lu_141[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 7, 7, 160)    92320       ['depthwise_conv2d_70[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_143 (ReLU)               (None, 7, 7, 160)    0           ['conv2d_155[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_71 (Depthwise  (None, 7, 7, 160)   1600        ['re_lu_143[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 7, 7, 160)    25760       ['depthwise_conv2d_71[0][0]']    \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 7, 7, 160)    0           ['conv2d_155[0][0]',             \n",
      "                                                                  'conv2d_157[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_145 (ReLU)               (None, 7, 7, 160)    0           ['add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_72 (Depthwise  (None, 7, 7, 160)   1600        ['re_lu_145[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 7, 7, 160)    25760       ['depthwise_conv2d_72[0][0]']    \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 7, 7, 160)    0           ['add_49[0][0]',                 \n",
      "                                                                  'conv2d_159[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 7, 7, 160)   640         ['add_50[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_146 (ReLU)               (None, 7, 7, 160)    0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 7, 7, 960)    154560      ['re_lu_146[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 7, 7, 960)   3840        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_147 (ReLU)               (None, 7, 7, 960)    0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_73 (Depthwise  (None, 7, 7, 960)   9600        ['re_lu_147[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 7, 7, 320)    307520      ['depthwise_conv2d_73[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 7, 7, 1280)   410880      ['conv2d_161[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 1, 1, 1280)  0           ['conv2d_162[0][0]']             \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 1, 1, 1280)   1639680     ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 1280)        0           ['conv2d_163[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1000)         1281000     ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,165,448\n",
      "Trainable params: 4,159,832\n",
      "Non-trainable params: 5,616\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1257 files belonging to 10 classes.\n",
      "Using 1132 files for training.\n",
      "Found 1257 files belonging to 10 classes.\n",
      "Using 125 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dir=r'D:\\dataset\\butterfly\\train'\n",
    "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "dir,\n",
    "labels=\"inferred\",\n",
    "label_mode=\"categorical\",\n",
    "class_names=None,\n",
    "color_mode=\"rgb\",\n",
    "batch_size=4,\n",
    "image_size=(224, 224),\n",
    "shuffle=True,\n",
    "seed=10,\n",
    "validation_split=0.1,\n",
    "subset='training',\n",
    "interpolation=\"gaussian\",\n",
    "follow_links=False,\n",
    "crop_to_aspect_ratio=False,)\n",
    "\n",
    "\n",
    "validation_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "dir,\n",
    "labels=\"inferred\",\n",
    "label_mode='categorical',\n",
    "class_names=None,\n",
    "color_mode=\"rgb\",\n",
    "batch_size=4,\n",
    "image_size=(224, 224),\n",
    "shuffle=True,\n",
    "seed=10,\n",
    "validation_split=0.1,\n",
    "subset='validation',\n",
    "interpolation=\"gaussian\",\n",
    "follow_links=False,\n",
    "crop_to_aspect_ratio=False,)\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255.)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy' ,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "283/283 [==============================] - 59s 135ms/step - loss: 2.2263 - acc: 0.1837 - val_loss: 2.3105 - val_acc: 0.1600\n",
      "Epoch 2/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 2.0562 - acc: 0.2111 - val_loss: 2.0784 - val_acc: 0.3120\n",
      "Epoch 3/100\n",
      "283/283 [==============================] - 40s 132ms/step - loss: 1.8299 - acc: 0.3322 - val_loss: 3.3571 - val_acc: 0.2720\n",
      "Epoch 4/100\n",
      "283/283 [==============================] - 36s 122ms/step - loss: 1.6111 - acc: 0.4099 - val_loss: 1.4808 - val_acc: 0.4320\n",
      "Epoch 5/100\n",
      "283/283 [==============================] - 40s 141ms/step - loss: 1.4775 - acc: 0.4585 - val_loss: 1.5114 - val_acc: 0.4800\n",
      "Epoch 6/100\n",
      "283/283 [==============================] - 40s 142ms/step - loss: 1.4318 - acc: 0.4859 - val_loss: 1.4976 - val_acc: 0.4560\n",
      "Epoch 7/100\n",
      "283/283 [==============================] - 42s 138ms/step - loss: 1.1856 - acc: 0.5512 - val_loss: 1.4489 - val_acc: 0.5040\n",
      "Epoch 8/100\n",
      "283/283 [==============================] - 35s 122ms/step - loss: 1.1496 - acc: 0.5813 - val_loss: 0.9696 - val_acc: 0.6400\n",
      "Epoch 9/100\n",
      "283/283 [==============================] - 36s 126ms/step - loss: 1.0699 - acc: 0.6157 - val_loss: 1.0676 - val_acc: 0.6960\n",
      "Epoch 10/100\n",
      "283/283 [==============================] - 39s 139ms/step - loss: 0.9521 - acc: 0.6767 - val_loss: 1.0578 - val_acc: 0.6080\n",
      "Epoch 11/100\n",
      "283/283 [==============================] - 37s 132ms/step - loss: 0.8630 - acc: 0.6882 - val_loss: 1.0617 - val_acc: 0.5600\n",
      "Epoch 12/100\n",
      "283/283 [==============================] - 24s 84ms/step - loss: 0.9170 - acc: 0.6846 - val_loss: 0.9700 - val_acc: 0.5920\n",
      "Epoch 13/100\n",
      "283/283 [==============================] - 28s 100ms/step - loss: 0.8000 - acc: 0.7085 - val_loss: 0.5457 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "283/283 [==============================] - 39s 136ms/step - loss: 0.6503 - acc: 0.7774 - val_loss: 0.5484 - val_acc: 0.8320\n",
      "Epoch 15/100\n",
      "283/283 [==============================] - 34s 119ms/step - loss: 0.6447 - acc: 0.7703 - val_loss: 0.5017 - val_acc: 0.8560\n",
      "Epoch 16/100\n",
      "283/283 [==============================] - 37s 132ms/step - loss: 0.5413 - acc: 0.8154 - val_loss: 0.7858 - val_acc: 0.7600\n",
      "Epoch 17/100\n",
      "283/283 [==============================] - 36s 125ms/step - loss: 0.5234 - acc: 0.8251 - val_loss: 0.5550 - val_acc: 0.8320\n",
      "Epoch 18/100\n",
      "283/283 [==============================] - 33s 115ms/step - loss: 0.4623 - acc: 0.8277 - val_loss: 0.9990 - val_acc: 0.7040\n",
      "Epoch 19/100\n",
      "283/283 [==============================] - 36s 126ms/step - loss: 0.4907 - acc: 0.8436 - val_loss: 0.6436 - val_acc: 0.8240\n",
      "Epoch 20/100\n",
      "283/283 [==============================] - 39s 137ms/step - loss: 0.4983 - acc: 0.8410 - val_loss: 0.6369 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "283/283 [==============================] - 36s 125ms/step - loss: 0.6380 - acc: 0.7968 - val_loss: 0.6187 - val_acc: 0.8320\n",
      "Epoch 22/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 0.2907 - acc: 0.9028 - val_loss: 0.5316 - val_acc: 0.8160\n",
      "Epoch 23/100\n",
      "283/283 [==============================] - 33s 118ms/step - loss: 0.2184 - acc: 0.9214 - val_loss: 0.8062 - val_acc: 0.7520\n",
      "Epoch 24/100\n",
      "283/283 [==============================] - 36s 125ms/step - loss: 0.3229 - acc: 0.8896 - val_loss: 0.3961 - val_acc: 0.8480\n",
      "Epoch 25/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.2697 - acc: 0.9028 - val_loss: 0.3550 - val_acc: 0.8720\n",
      "Epoch 26/100\n",
      "283/283 [==============================] - 34s 121ms/step - loss: 0.3227 - acc: 0.8975 - val_loss: 0.5139 - val_acc: 0.8400\n",
      "Epoch 27/100\n",
      "283/283 [==============================] - 39s 136ms/step - loss: 0.2375 - acc: 0.9134 - val_loss: 0.6568 - val_acc: 0.7600\n",
      "Epoch 28/100\n",
      "283/283 [==============================] - 36s 126ms/step - loss: 0.8662 - acc: 0.7686 - val_loss: 0.5627 - val_acc: 0.8480\n",
      "Epoch 29/100\n",
      "283/283 [==============================] - 39s 139ms/step - loss: 0.2096 - acc: 0.9231 - val_loss: 0.5942 - val_acc: 0.8080\n",
      "Epoch 30/100\n",
      "283/283 [==============================] - 41s 144ms/step - loss: 0.1496 - acc: 0.9488 - val_loss: 0.3068 - val_acc: 0.8800\n",
      "Epoch 31/100\n",
      "283/283 [==============================] - 33s 117ms/step - loss: 0.1586 - acc: 0.9399 - val_loss: 0.7031 - val_acc: 0.8240\n",
      "Epoch 32/100\n",
      "283/283 [==============================] - 38s 130ms/step - loss: 0.1842 - acc: 0.9355 - val_loss: 0.7760 - val_acc: 0.7760\n",
      "Epoch 33/100\n",
      "283/283 [==============================] - 33s 118ms/step - loss: 0.1983 - acc: 0.9329 - val_loss: 0.3827 - val_acc: 0.8720\n",
      "Epoch 34/100\n",
      "283/283 [==============================] - 37s 132ms/step - loss: 0.1353 - acc: 0.9496 - val_loss: 0.5114 - val_acc: 0.8560\n",
      "Epoch 35/100\n",
      "283/283 [==============================] - 33s 117ms/step - loss: 0.2724 - acc: 0.9099 - val_loss: 0.5586 - val_acc: 0.8640\n",
      "Epoch 36/100\n",
      "283/283 [==============================] - 33s 118ms/step - loss: 0.1915 - acc: 0.9364 - val_loss: 0.5884 - val_acc: 0.8560\n",
      "Epoch 37/100\n",
      "283/283 [==============================] - 36s 126ms/step - loss: 0.2985 - acc: 0.9161 - val_loss: 1.4019 - val_acc: 0.7520\n",
      "Epoch 38/100\n",
      "283/283 [==============================] - 40s 141ms/step - loss: 0.1675 - acc: 0.9382 - val_loss: 0.5299 - val_acc: 0.8640\n",
      "Epoch 39/100\n",
      "283/283 [==============================] - 34s 119ms/step - loss: 0.2050 - acc: 0.9329 - val_loss: 0.5962 - val_acc: 0.8640\n",
      "Epoch 40/100\n",
      "283/283 [==============================] - 39s 136ms/step - loss: 0.1668 - acc: 0.9461 - val_loss: 0.7431 - val_acc: 0.8080\n",
      "Epoch 41/100\n",
      "283/283 [==============================] - 38s 135ms/step - loss: 0.0718 - acc: 0.9726 - val_loss: 0.4698 - val_acc: 0.8880\n",
      "Epoch 42/100\n",
      "283/283 [==============================] - 41s 145ms/step - loss: 0.1552 - acc: 0.9549 - val_loss: 1.0451 - val_acc: 0.7600\n",
      "Epoch 43/100\n",
      "283/283 [==============================] - 36s 128ms/step - loss: 1.8785 - acc: 0.7465 - val_loss: 0.6067 - val_acc: 0.8240\n",
      "Epoch 44/100\n",
      "283/283 [==============================] - 35s 123ms/step - loss: 0.1903 - acc: 0.9452 - val_loss: 0.6899 - val_acc: 0.8640\n",
      "Epoch 45/100\n",
      "283/283 [==============================] - 38s 136ms/step - loss: 0.1333 - acc: 0.9567 - val_loss: 0.5357 - val_acc: 0.8960\n",
      "Epoch 46/100\n",
      "283/283 [==============================] - 22s 77ms/step - loss: 0.0637 - acc: 0.9806 - val_loss: 0.4996 - val_acc: 0.8960\n",
      "Epoch 47/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.1153 - acc: 0.9585 - val_loss: 0.6858 - val_acc: 0.8480\n",
      "Epoch 48/100\n",
      "283/283 [==============================] - 38s 135ms/step - loss: 0.0502 - acc: 0.9867 - val_loss: 0.5088 - val_acc: 0.8960\n",
      "Epoch 49/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.0983 - acc: 0.9620 - val_loss: 0.5990 - val_acc: 0.8640\n",
      "Epoch 50/100\n",
      "283/283 [==============================] - 34s 120ms/step - loss: 0.2077 - acc: 0.9311 - val_loss: 0.6002 - val_acc: 0.8560\n",
      "Epoch 51/100\n",
      "283/283 [==============================] - 36s 129ms/step - loss: 0.1553 - acc: 0.9496 - val_loss: 0.4223 - val_acc: 0.8960\n",
      "Epoch 52/100\n",
      "283/283 [==============================] - 41s 144ms/step - loss: 0.0758 - acc: 0.9700 - val_loss: 0.8430 - val_acc: 0.8240\n",
      "Epoch 53/100\n",
      "283/283 [==============================] - 39s 135ms/step - loss: 0.0738 - acc: 0.9717 - val_loss: 0.7775 - val_acc: 0.8480\n",
      "Epoch 54/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.0922 - acc: 0.9726 - val_loss: 0.4285 - val_acc: 0.8720\n",
      "Epoch 55/100\n",
      "283/283 [==============================] - 34s 121ms/step - loss: 0.0582 - acc: 0.9788 - val_loss: 0.6164 - val_acc: 0.8400\n",
      "Epoch 56/100\n",
      "283/283 [==============================] - 39s 137ms/step - loss: 0.1609 - acc: 0.9488 - val_loss: 0.9802 - val_acc: 0.7840\n",
      "Epoch 57/100\n",
      "283/283 [==============================] - 35s 122ms/step - loss: 0.4783 - acc: 0.8763 - val_loss: 1.7574 - val_acc: 0.6640\n",
      "Epoch 58/100\n",
      "283/283 [==============================] - 36s 126ms/step - loss: 0.1935 - acc: 0.9479 - val_loss: 1.0683 - val_acc: 0.7600\n",
      "Epoch 59/100\n",
      "283/283 [==============================] - 42s 150ms/step - loss: 0.1263 - acc: 0.9594 - val_loss: 0.5744 - val_acc: 0.8880\n",
      "Epoch 60/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.0465 - acc: 0.9823 - val_loss: 0.4614 - val_acc: 0.8720\n",
      "Epoch 61/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 0.0441 - acc: 0.9859 - val_loss: 0.3957 - val_acc: 0.9120\n",
      "Epoch 62/100\n",
      "283/283 [==============================] - 32s 114ms/step - loss: 0.1080 - acc: 0.9726 - val_loss: 0.4073 - val_acc: 0.8880\n",
      "Epoch 63/100\n",
      "283/283 [==============================] - 35s 125ms/step - loss: 0.1093 - acc: 0.9682 - val_loss: 1.2847 - val_acc: 0.7840\n",
      "Epoch 64/100\n",
      "283/283 [==============================] - 33s 117ms/step - loss: 0.1099 - acc: 0.9673 - val_loss: 0.6053 - val_acc: 0.8720\n",
      "Epoch 65/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.0895 - acc: 0.9664 - val_loss: 0.6781 - val_acc: 0.8560\n",
      "Epoch 66/100\n",
      "283/283 [==============================] - 34s 119ms/step - loss: 0.1188 - acc: 0.9629 - val_loss: 1.1622 - val_acc: 0.7680\n",
      "Epoch 67/100\n",
      "283/283 [==============================] - 44s 154ms/step - loss: 2.1502 - acc: 0.7491 - val_loss: 0.4681 - val_acc: 0.8800\n",
      "Epoch 68/100\n",
      "283/283 [==============================] - 33s 115ms/step - loss: 0.1302 - acc: 0.9594 - val_loss: 0.6558 - val_acc: 0.9040\n",
      "Epoch 69/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 0.0292 - acc: 0.9929 - val_loss: 0.6139 - val_acc: 0.8960\n",
      "Epoch 70/100\n",
      "283/283 [==============================] - 38s 134ms/step - loss: 0.0860 - acc: 0.9717 - val_loss: 0.5738 - val_acc: 0.8720\n",
      "Epoch 71/100\n",
      "283/283 [==============================] - 39s 138ms/step - loss: 0.0521 - acc: 0.9867 - val_loss: 0.6600 - val_acc: 0.8800\n",
      "Epoch 72/100\n",
      "283/283 [==============================] - 36s 124ms/step - loss: 0.0393 - acc: 0.9894 - val_loss: 0.5085 - val_acc: 0.9040\n",
      "Epoch 73/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.0473 - acc: 0.9859 - val_loss: 0.8278 - val_acc: 0.8720\n",
      "Epoch 74/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.1682 - acc: 0.9620 - val_loss: 1.1071 - val_acc: 0.8080\n",
      "Epoch 75/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.1273 - acc: 0.9585 - val_loss: 0.6569 - val_acc: 0.8960\n",
      "Epoch 76/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.0587 - acc: 0.9814 - val_loss: 0.5112 - val_acc: 0.8960\n",
      "Epoch 77/100\n",
      "283/283 [==============================] - 34s 119ms/step - loss: 0.0500 - acc: 0.9788 - val_loss: 0.5878 - val_acc: 0.8800\n",
      "Epoch 78/100\n",
      "283/283 [==============================] - 33s 118ms/step - loss: 0.0866 - acc: 0.9761 - val_loss: 0.6913 - val_acc: 0.8640\n",
      "Epoch 79/100\n",
      "283/283 [==============================] - 25s 88ms/step - loss: 0.0820 - acc: 0.9753 - val_loss: 0.7456 - val_acc: 0.8640\n",
      "Epoch 80/100\n",
      "283/283 [==============================] - 35s 124ms/step - loss: 0.0572 - acc: 0.9797 - val_loss: 0.5094 - val_acc: 0.9200\n",
      "Epoch 81/100\n",
      "283/283 [==============================] - 37s 129ms/step - loss: 0.0773 - acc: 0.9806 - val_loss: 0.7289 - val_acc: 0.8640\n",
      "Epoch 82/100\n",
      "283/283 [==============================] - 37s 130ms/step - loss: 0.1478 - acc: 0.9532 - val_loss: 0.6786 - val_acc: 0.8160\n",
      "Epoch 83/100\n",
      "283/283 [==============================] - 34s 120ms/step - loss: 0.1648 - acc: 0.9523 - val_loss: 0.4395 - val_acc: 0.8960\n",
      "Epoch 84/100\n",
      "283/283 [==============================] - 35s 122ms/step - loss: 0.0352 - acc: 0.9894 - val_loss: 0.3239 - val_acc: 0.9280\n",
      "Epoch 85/100\n",
      "283/283 [==============================] - 32s 111ms/step - loss: 0.0415 - acc: 0.9850 - val_loss: 0.4629 - val_acc: 0.8960\n",
      "Epoch 86/100\n",
      "283/283 [==============================] - 43s 153ms/step - loss: 0.0889 - acc: 0.9700 - val_loss: 1.1727 - val_acc: 0.8160\n",
      "Epoch 87/100\n",
      "283/283 [==============================] - 37s 129ms/step - loss: 2.3088 - acc: 0.7659 - val_loss: 0.9575 - val_acc: 0.8080\n",
      "Epoch 88/100\n",
      "283/283 [==============================] - 37s 131ms/step - loss: 0.2108 - acc: 0.9452 - val_loss: 0.5155 - val_acc: 0.8880\n",
      "Epoch 89/100\n",
      "283/283 [==============================] - 39s 138ms/step - loss: 0.0411 - acc: 0.9850 - val_loss: 0.4778 - val_acc: 0.9120\n",
      "Epoch 90/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 0.0363 - acc: 0.9859 - val_loss: 0.4511 - val_acc: 0.9200\n",
      "Epoch 91/100\n",
      "283/283 [==============================] - 39s 139ms/step - loss: 0.0307 - acc: 0.9859 - val_loss: 0.4585 - val_acc: 0.9120\n",
      "Epoch 92/100\n",
      "283/283 [==============================] - 45s 160ms/step - loss: 0.0270 - acc: 0.9929 - val_loss: 0.5246 - val_acc: 0.8800\n",
      "Epoch 93/100\n",
      "283/283 [==============================] - 38s 135ms/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.6977 - val_acc: 0.8560\n",
      "Epoch 94/100\n",
      "283/283 [==============================] - 40s 143ms/step - loss: 0.0574 - acc: 0.9867 - val_loss: 0.6657 - val_acc: 0.9120\n",
      "Epoch 95/100\n",
      "283/283 [==============================] - 41s 145ms/step - loss: 0.0945 - acc: 0.9761 - val_loss: 0.7535 - val_acc: 0.8320\n",
      "Epoch 96/100\n",
      "283/283 [==============================] - 41s 144ms/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.5940 - val_acc: 0.8880\n",
      "Epoch 97/100\n",
      "283/283 [==============================] - 41s 141ms/step - loss: 0.1349 - acc: 0.9611 - val_loss: 0.7106 - val_acc: 0.8640\n",
      "Epoch 98/100\n",
      "283/283 [==============================] - 38s 133ms/step - loss: 0.0482 - acc: 0.9823 - val_loss: 0.6956 - val_acc: 0.8800\n",
      "Epoch 99/100\n",
      "283/283 [==============================] - 43s 151ms/step - loss: 0.1159 - acc: 0.9735 - val_loss: 0.5981 - val_acc: 0.8960\n",
      "Epoch 100/100\n",
      "283/283 [==============================] - 37s 129ms/step - loss: 0.0487 - acc: 0.9832 - val_loss: 1.0700 - val_acc: 0.8400\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history=model.fit(train_ds,validation_data=validation_ds,epochs=100,batch_size=4,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training','validation'],loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training','validation'],loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f63f62229035d384e646c189fd217ceea058ae56feeee8d9eb8b5a7f24aaefef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
