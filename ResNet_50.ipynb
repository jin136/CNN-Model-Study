{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential,Model,initializers,layers,Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full pre-activation방식\n",
    "def conv2_x(x,st):\n",
    "\n",
    "    x1=layers.Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same')(x)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=64,kernel_size=(3,3),strides=(st,st),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "  \n",
    "    x2=layers.Add()([x,x1])\n",
    "    x2=layers.ReLU(x2)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3_x(x,st):\n",
    "    x1=layers.Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),padding='same')(x)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=512,kernel_size=(3,3),strides=(st,st),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "  \n",
    "    x2=layers.Add()([x,x1])\n",
    "    x2=layers.ReLU(x2)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv4_x(x,st):\n",
    "    x1=layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),padding='same')(x)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=1024,kernel_size=(3,3),strides=(st,st),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "  \n",
    "    x2=layers.Add()([x,x1])\n",
    "    x2=layers.ReLU(x2)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv5_x(x,st):\n",
    "    x1=layers.Conv2D(filters=512,kernel_size=(1,1),strides=(1,1),padding='same')(x)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "    x1=layers.Conv2D(filters=2048,kernel_size=(3,3),strides=(st,st),padding='same')(x1)\n",
    "    x1=layers.BatchNormalization()(x1)\n",
    "    x1=layers.ReLU()(x1)\n",
    "  \n",
    "    x2=layers.Add()([x,x1])\n",
    "    x2=layers.ReLU(x2)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m x\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mReLU()(x)\n\u001b[0;32m      5\u001b[0m x\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m))(x)\n\u001b[1;32m----> 6\u001b[0m x\u001b[39m=\u001b[39mconv2_x(x,(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      7\u001b[0m x\u001b[39m=\u001b[39mconv2_x(x,(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m x\u001b[39m=\u001b[39mconv2_x(x,(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m))\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mconv2_x\u001b[1;34m(x, st)\u001b[0m\n\u001b[0;32m     12\u001b[0m x1\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mReLU()(x1)\n\u001b[0;32m     14\u001b[0m x2\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mAdd()([x,x1])\n\u001b[1;32m---> 15\u001b[0m x2\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39;49mReLU(x2)\n\u001b[0;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m x2\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\layers\\activation\\relu.py:79\u001b[0m, in \u001b[0;36mReLU.__init__\u001b[1;34m(self, max_value, negative_slope, threshold, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     76\u001b[0m     \u001b[39mself\u001b[39m, max_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, negative_slope\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, threshold\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m     77\u001b[0m ):\n\u001b[0;32m     78\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mif\u001b[39;00m max_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m max_value \u001b[39m<\u001b[39;49m \u001b[39m0.0\u001b[39;49m:\n\u001b[0;32m     80\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmax_value of a ReLU layer cannot be a negative \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue. Received: \u001b[39m\u001b[39m{\u001b[39;00mmax_value\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m         )\n\u001b[0;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m negative_slope \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m negative_slope \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\keras_tensor.py:244\u001b[0m, in \u001b[0;36mKerasTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKeras symbolic inputs/outputs do not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimplement `__len__`. You may be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto a TF API that does not register dispatching, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpreventing Keras from automatically \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconverting the API call to a lambda layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the Functional Model. This error will also get raised \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif you try asserting a symbolic input/output directly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "input=Input(shape=(112,112,3))\n",
    "x=layers.Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),padding='same')(input)\n",
    "x=layers.BatchNormalization()(x)\n",
    "x=layers.ReLU()(x)\n",
    "x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "x=conv2_x(x,(1,1))\n",
    "x=conv2_x(x,(1,1))\n",
    "x=conv2_x(x,(2,2))\n",
    "\n",
    "x=conv3_x(x,(1,1))\n",
    "x=conv3_x(x,(1,1))\n",
    "x=conv3_x(x,(1,1))\n",
    "x=conv3_x(x,(2,2))\n",
    "\n",
    "x=conv4_x(x,(1,1))\n",
    "x=conv4_x(x,(1,1))\n",
    "x=conv4_x(x,(1,1))\n",
    "x=conv4_x(x,(1,1))\n",
    "x=conv4_x(x,(1,1))\n",
    "x=conv4_x(x,(2,2))\n",
    "\n",
    "x=conv5_x(x,(1,1))\n",
    "x=conv5_x(x,(1,1))\n",
    "x=conv5_x(x,(2,2))\n",
    "\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "output=layers.Dense(units=10,activation='softmax',name='output')\n",
    "\n",
    "model = tf.keras.models.Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file='ResNet_50.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy' ,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=1,batch_size=8,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2aa449cdabfa2015c02c49b6052644087a8272ff24b4438d56a7aabf7a36706b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
