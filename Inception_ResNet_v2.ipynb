{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential,Model,initializers,layers,Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(x):\n",
    "    x=layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x)\n",
    "    x=layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x=layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "\n",
    "    x1=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "    x2=layers.Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x3=tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    x4=layers.Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x3)\n",
    "    x4=layers.Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x4)\n",
    "\n",
    "    x5=layers.Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x3)\n",
    "    x5=layers.Conv2D(filters=64,kernel_size=(7,1),strides=(1,1),padding='same',activation='relu')(x5)\n",
    "    x5=layers.Conv2D(filters=64,kernel_size=(1,7),strides=(1,1),padding='same',activation='relu')(x5)\n",
    "    x5=layers.Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x5)\n",
    "    x6=tf.keras.layers.Concatenate()([x4, x5])\n",
    "\n",
    "    x7=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x6)\n",
    "    x8=layers.Conv2D(filters=192,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x6)\n",
    "    x9=tf.keras.layers.Concatenate()([x7, x8])\n",
    "\n",
    "    return x9\n",
    "\n",
    "\n",
    "def Inception_ResNet_Block_A(x):\n",
    "    x=layers.activation.ReLU()(x)\n",
    "\n",
    "    x1=layers.Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "\n",
    "    x2=layers.Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "\n",
    "\n",
    "    x3=layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x3=layers.Conv2D(filters=48,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x3)\n",
    "    x3=layers.Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x3)\n",
    "\n",
    "    x4=tf.keras.layers.Concatenate()([x,x1,x2,x3])\n",
    "    x4=layers.Conv2D(filters=384,kernel_size=(1,1),strides=(1,1),padding='same')(x4)\n",
    "    \n",
    "    x5=layers.Add()([x,x4]) \n",
    "    x5=layers.activation.ReLU()(x5)\n",
    "    return x5\n",
    "\n",
    "\n",
    "\n",
    "def Inception_ResNet_Block_B(x):\n",
    "    x=layers.activation.ReLU()(x)\n",
    "\n",
    "    x1=layers.Conv2D(filters=192,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "\n",
    "    x2=layers.Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=160,kernel_size=(1,7),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "    x2=layers.Conv2D(filters=192,kernel_size=(7,1),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "    \n",
    "    x3=tf.keras.layers.Concatenate()([x1,x2])\n",
    "\n",
    "    x3=layers.Conv2D(filters=1154,kernel_size=(1,1),strides=(1,1),padding='same')(x3)\n",
    "    \n",
    "    x4=layers.Add()([x,x3])\n",
    "\n",
    "    x4=layers.activation.ReLU()(x4)\n",
    "\n",
    "    return x4\n",
    "\n",
    "\n",
    "def Inception_ResNet_Block_C(x):\n",
    "    x=layers.activation.ReLU()(x)\n",
    "\n",
    "    x1=layers.Conv2D(filters=192,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "\n",
    "    x2=layers.Conv2D(filters=192,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=224,kernel_size=(1,3),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "    x2=layers.Conv2D(filters=256,kernel_size=(3,1),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "    \n",
    "    x3=tf.keras.layers.Concatenate()([x1,x2])\n",
    "\n",
    "    x3=layers.Conv2D(filters=2048,kernel_size=(1,1),strides=(1,1),padding='same')(x3)\n",
    "    \n",
    "    x4=layers.Add()([x,x3])\n",
    "\n",
    "    x4=layers.activation.ReLU()(x4)\n",
    "\n",
    "    return x4\n",
    "\n",
    "\n",
    "def Reduction_Block_A(input_1,input_2,input_3,input_4,input_5):\n",
    "    x=tf.keras.layers.Concatenate()([input_1,input_2,input_3,input_4,input_5]) \n",
    "    x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "\n",
    "    x1=layers.Conv2D(filters=384,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x)\n",
    "\n",
    "    x2=layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "    x2=layers.Conv2D(filters=384,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x2)\n",
    "\n",
    "    x3=tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    return x3 \n",
    "\n",
    "\n",
    "\n",
    "def Reduction_Block_B(x):\n",
    "    x1=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "\n",
    "    x2=layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=384,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x2)\n",
    "    \n",
    "\n",
    "    x3=layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x3=layers.Conv2D(filters=288,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x3)\n",
    "\n",
    "    x4=layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x4=layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x4=layers.Conv2D(filters=320,kernel_size=(3,3),strides=(2,2),padding='same',activation='relu')(x)\n",
    "    \n",
    "\n",
    "    x5=tf.keras.layers.Concatenate()([x1,x2,x2,x3,x4])\n",
    "    \n",
    "    return x5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 75, 75, 64), (None, 150, 150, 96)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m     x6\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m x6\n\u001b[1;32m---> 24\u001b[0m model\u001b[39m=\u001b[39mInception_ResNet()\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mInception_ResNet\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mInception_ResNet\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m299\u001b[39m,\u001b[39m299\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m     x\u001b[39m=\u001b[39mStem(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m     x1\u001b[39m=\u001b[39mInception_ResNet_A(x)\n\u001b[0;32m      6\u001b[0m     x2\u001b[39m=\u001b[39mInception_ResNet_A(x)\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mStem\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m x1\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m),padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m      7\u001b[0m x2\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m,kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m----> 8\u001b[0m x3\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConcatenate()([x1, x2])\n\u001b[0;32m     10\u001b[0m x4\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,kernel_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x3)\n\u001b[0;32m     11\u001b[0m x4\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m,kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x4)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\layers\\merging\\concatenate.py:131\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    125\u001b[0m unique_dims \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[0;32m    126\u001b[0m     shape[axis]\n\u001b[0;32m    127\u001b[0m     \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m shape_set\n\u001b[0;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m shape[axis] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_dims) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 75, 75, 64), (None, 150, 150, 96)]"
     ]
    }
   ],
   "source": [
    "def Inception_ResNet():\n",
    "    input=layers.Input(shape=(299,299,3))\n",
    "    x=Stem(input)\n",
    "    \n",
    "    x1=Inception_ResNet_Block_A(x)\n",
    "    x2=Inception_ResNet_Block_A(x)\n",
    "    x3=Inception_ResNet_Block_A(x)\n",
    "    x4=Inception_ResNet_Block_A(x)\n",
    "    x5=Inception_ResNet_Block_A(x)\n",
    "    \n",
    "    x6=Reduction_Block_A(x1,x2,x3,x4,x5)\n",
    "    for i in range(10):\n",
    "        x6=Inception_ResNet_Block_B(x6)\n",
    "    x6=Reduction_Block_B(x6)\n",
    "    for i in range(5):\n",
    "        x6=Inception_ResNet_Block_C(x6)\n",
    "    \n",
    "    x6=layers.GlobalAveragePooling2D()(x6)\n",
    "    x6=layers.Dropout(0.8)\n",
    "    x6=layers.Dense(units=10,activation='softmax')\n",
    "\n",
    "    return x6\n",
    "    \n",
    "model=Inception_ResNet()\n",
    "model = tf.keras.models.Model(inputs,[output,ax1,ax2],name = 'GoogleNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2aa449cdabfa2015c02c49b6052644087a8272ff24b4438d56a7aabf7a36706b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
